# ===========================================
# LLM Provider Configuration
# ===========================================
LLM_PROVIDER=openai                    # Options: openai, anthropic
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-key-here

# ===========================================
# API Keys for Tools
# ===========================================
NASA_API_KEY=your-nasa-api-key         # Get free key at https://api.nasa.gov/
LOGMEAL_API_KEY=your-logmeal-key       # Get key at https://logmeal.es/

# ===========================================
# Evaluation Configuration
# ===========================================
# Phoenix and DeepEval use the LLM provider keys above for LLM-as-judge
EVAL_RATE_LIMIT_INITIAL_RPS=0.1                # Requests per second for eval LLM calls (0.1 = 10s between requests)
PHOENIX_EVALUATION_METHOD=categorical          # Options: categorical, discrete, continuous
MINIMUM_AGREEMENT_PASS_THRESHOLD=0.8           # Minimum agreement (0.0-1.0) between frameworks to pass
MINIMUM_METRIC_PASS_THRESHOLD=0.7              # Minimum score (0.0-1.0) for any individual metric to pass

# ===========================================
# Optional Configuration
# ===========================================
LOG_LEVEL=INFO
MAX_RETRIES=3
REQUEST_TIMEOUT=30
MAX_TOKENS=4096
LLM_TEMPERATURE=0.1
